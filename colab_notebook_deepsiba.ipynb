{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uUL-XLIbDwK"
   },
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPFWQDo-a-yV",
    "outputId": "b01d9c70-d4c7-4ef2-9196-4de90cdd7f5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
      "python version: 3.6.9\n",
      "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "done\n",
      "installing miniconda to /root/miniconda\n",
      "done\n",
      "installing rdkit\n",
      "done\n",
      "rdkit-2020.09.1 installation finished!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import subprocess\n",
    "import shutil\n",
    "from logging import getLogger, StreamHandler, INFO\n",
    "\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "logger.addHandler(StreamHandler())\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "\n",
    "def install(\n",
    "        chunk_size=4096,\n",
    "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
    "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
    "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
    "        rdkit_version=None,\n",
    "        add_python_path=True,\n",
    "        force=False):\n",
    "    \"\"\"install rdkit from miniconda\n",
    "    ```\n",
    "    import rdkit_installer\n",
    "    rdkit_installer.install()\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    python_path = os.path.join(\n",
    "        conda_path,\n",
    "        \"lib\",\n",
    "        \"python{0}.{1}\".format(*sys.version_info),\n",
    "        \"site-packages\",\n",
    "    )\n",
    "\n",
    "    if add_python_path and python_path not in sys.path:\n",
    "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
    "        sys.path.append(python_path)\n",
    "\n",
    "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
    "        logger.info(\"rdkit is already installed\")\n",
    "        if not force:\n",
    "            return\n",
    "\n",
    "        logger.info(\"force re-install\")\n",
    "\n",
    "    url = url_base + file_name\n",
    "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
    "\n",
    "    logger.info(\"python version: {}\".format(python_version))\n",
    "\n",
    "    if os.path.isdir(conda_path):\n",
    "        logger.warning(\"remove current miniconda\")\n",
    "        shutil.rmtree(conda_path)\n",
    "    elif os.path.isfile(conda_path):\n",
    "        logger.warning(\"remove {}\".format(conda_path))\n",
    "        os.remove(conda_path)\n",
    "\n",
    "    logger.info('fetching installer from {}'.format(url))\n",
    "    res = requests.get(url, stream=True)\n",
    "    res.raise_for_status()\n",
    "    with open(file_name, 'wb') as f:\n",
    "        for chunk in res.iter_content(chunk_size):\n",
    "            f.write(chunk)\n",
    "    logger.info('done')\n",
    "\n",
    "    logger.info('installing miniconda to {}'.format(conda_path))\n",
    "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
    "    logger.info('done')\n",
    "\n",
    "    logger.info(\"installing rdkit\")\n",
    "    subprocess.check_call([\n",
    "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
    "        \"install\",\n",
    "        \"--yes\",\n",
    "        \"-c\", \"rdkit\",\n",
    "        \"python=={}\".format(python_version),\n",
    "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
    "    logger.info(\"done\")\n",
    "\n",
    "    import rdkit\n",
    "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0F510HBNbGA7",
    "outputId": "c58173ff-f5d3-44af-ab6f-669a5f6fc5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG5guXisbJ4t"
   },
   "outputs": [],
   "source": [
    "!cp -r \"drive/My Drive/deepSIBA_pytorch/NGF\" /content\n",
    "!cp -r \"drive/My Drive/deepSIBA_pytorch/NGF_layers\" /content\n",
    "!cp -r \"drive/My Drive/deepSIBA_pytorch/utility\" /content\n",
    "!cp -r \"drive/My Drive/deepSIBA_pytorch/utils\" /content\n",
    "!cp -r \"drive/My Drive/deepsiba_tf2/data\" /content\n",
    "!cp \"drive/My Drive/deepSIBA_pytorch/deepSIBA_model.py\" /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5elLBIKsmeUZ"
   },
   "outputs": [],
   "source": [
    "#!rm -r NGF_layers\n",
    "#!rm -r utility\n",
    "#!rm -r utils\n",
    "#!rm -r data\n",
    "#!rm deepSIBA_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "POgMJkNybKwp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from numpy import inf, ndarray\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "import re\n",
    "#from NGF.utils import filter_func_args, mol_shapes_to_dims\n",
    "#import NGF.utils\n",
    "import NGF_layers.features\n",
    "import NGF_layers.graph_layers\n",
    "from NGF_layers.features import one_of_k_encoding, one_of_k_encoding_unk, atom_features, bond_features, num_atom_features, num_bond_features, padaxis, tensorise_smiles #, concat_mol_tensors\n",
    "from NGF_layers.graph_layers import neighbour_lookup, NeuralGraphHidden\n",
    "from math import ceil\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utility.gaussian import GaussianLayer, custom_loss, ConGaussianLayer\n",
    "from utility.evaluator import r_square, get_cindex, pearson_r,custom_mse, mse_sliced, model_evaluate\n",
    "from utility.Generator import train_generator,preds_generator\n",
    "from deepSIBA_model import enc_graph, siamese_model\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNToVljcbglb"
   },
   "source": [
    "# Load train and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BAVULcElbbVX"
   },
   "outputs": [],
   "source": [
    "#model_params\n",
    "model_params = {\n",
    "    \"max_atoms\" : int(60), \"num_atom_features\" : int(62), \"max_degree\" : int(5), \"num_bond_features\" : int(6),\n",
    "    \"graph_conv_width\" : [128,128,128], \"conv1d_in\" : int(60), \"conv1d_out\" : int(32), \"kernel_size\" : int(1), \"dropout_encoder\" : 0.25,\n",
    "    \"conv1d_dist_in\" : [32,16], \"conv1d_dist_out\" : [16,16], \"conv1d_dist_kernels\" : [1,1], \"dropout_dist\" : 0.25, \"pool_size\" : int(4),\n",
    "    \"dense_size\" : [256,128,128], \"l2reg\" : 0.01, \"dist_thresh\" : 0.2, \"lr\" : 0.001 ,\"ConGauss\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Sr32VyDYbi4A"
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"cell_line\" : \"a375\", \"split\" : \"train_test_split\", \"number_folds\" : [0],\n",
    "    \"output_dir\" : \"results\",\n",
    "    \"batch_size\" : int(128), \"epochs\" : int(20), \n",
    "    \"N_ensemble\" : int(1), \"nmodel_start\" : int(0), \"prec_threshold\" : 0.2,\n",
    "    \"Pre_training\" : False,\n",
    "    \"Pre_trained_cell_dir\" : '',\n",
    "    \"pattern_to_load\" : 'siam_no_augment_',\n",
    "    \"model_id_to_load\" : \"20\",\n",
    "    \"test_value_norm\" : True,\n",
    "    \"predict_batch_size\":int(1024)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2Dn8Ckqbnw-"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uzqITRqFbklm"
   },
   "outputs": [],
   "source": [
    "get_all = []\n",
    "if train_params[\"split\"] == \"train_test_split\":\n",
    "  outer_loop = train_params[\"number_folds\"]\n",
    "elif train_params[\"split\"] == \"5_fold_cv_split\":\n",
    "  outer_loop = train_params[\"number_folds\"]\n",
    "elif train_params[\"split\"] == \"alldata\":\n",
    "  outer_loop = train_params[\"number_folds\"]\n",
    "#Load unique smiles and tensorize them\n",
    "smiles = pd.read_csv(\"data/\" + train_params[\"cell_line\"] + \"/\" + train_params[\"cell_line\"] + \"q1smiles.csv\", index_col=0)\n",
    "X_atoms, X_bonds, X_edges = tensorise_smiles(smiles.x, model_params[\"max_degree\"], model_params[\"max_atoms\"])\n",
    "smiles=list(smiles['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vZHg9So9brV9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/\" + train_params[\"cell_line\"] + \"/\" + \"train_test_split/\" + \"train.csv\",index_col=0).reset_index(drop=True)\n",
    "df_cold = pd.read_csv(\"data/\" + train_params[\"cell_line\"] + \"/\" + \"train_test_split/\" + \"test.csv\",index_col=0).reset_index(drop=True)\n",
    "smiles_cold = list(set(list(df_cold['rdkit.x'])+list(df_cold['rdkit.y'])))\n",
    "X_atoms_cold, X_bonds_cold, X_edges_cold = tensorise_smiles(smiles_cold,  model_params[\"max_degree\"], model_params[\"max_atoms\"])\n",
    "#X_atoms_cold=X_atoms_cold.astype('float64')\n",
    "#X_bonds_cold=X_bonds_cold.astype('float64')\n",
    "#X_edges_cold=X_edges_cold.astype('int64')\n",
    "if train_params[\"test_value_norm\"]:\n",
    "  Y_cold = df_cold.value\n",
    "else:\n",
    "  Y_cold = df_cold.value\n",
    "  Y_cold = Y_cold/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Zi-Nsmo4btqZ"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "Path(train_params[\"output_dir\"] + \"/\" + \"fold_%s/models\"%i).mkdir(parents=True, exist_ok=True)\n",
    "cold_preds_mus = []\n",
    "cold_preds_sigmas = []\n",
    "n = train_params[\"nmodel_start\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWnFEBkmbyVa"
   },
   "source": [
    "# Define,Compile,Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "paXMLg2-bvyd"
   },
   "outputs": [],
   "source": [
    "deepsiba = siamese_model(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-iVqiwjwk0T",
    "outputId": "1d07ca21-cc47-4fe0-e4a0-f0700121f0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda mode\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "  if torch.cuda.is_available():\n",
    "    print('cuda mode')\n",
    "    return torch.device('cuda')\n",
    "  else:\n",
    "    print('cpu mode')\n",
    "  return torch.device('cpu')\n",
    "device=get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ooinemLwxJbf"
   },
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "  if isinstance(data,(list,tuple)):\n",
    "    return [to_device(x,device) for x in data]\n",
    "  return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3S4VhB7fwDrD"
   },
   "outputs": [],
   "source": [
    "class train_generator(Dataset):\n",
    "\n",
    "  def __init__(self, data,smiles,X_atoms, X_bonds, X_edges):\n",
    "    self.df=data\n",
    "    self.smiles=smiles\n",
    "    self.X_atoms=X_atoms\n",
    "    self.X_bonds=X_bonds\n",
    "    self.X_edges=X_edges\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    smi1=self.df['rdkit.x'][index]\n",
    "    smi2=self.df['rdkit.y'][index]\n",
    "    d=self.df.value[index]/2\n",
    "    ind1=self.smiles.index(smi1)\n",
    "    ind2=self.smiles.index(smi2)\n",
    "    atom_1=torch.tensor(self.X_atoms[ind1]).type(torch.FloatTensor)\n",
    "    bond_1=torch.tensor(self.X_bonds[ind1]).type(torch.FloatTensor)\n",
    "    edge_1=torch.tensor(self.X_edges[ind1]).type(torch.IntTensor)\n",
    "    atom_2=torch.tensor(self.X_atoms[ind2]).type(torch.FloatTensor)\n",
    "    bond_2=torch.tensor(self.X_bonds[ind2]).type(torch.FloatTensor)\n",
    "    edge_2=torch.tensor(self.X_edges[ind2]).type(torch.IntTensor)\n",
    "    return atom_1,bond_1,edge_1,atom_2,bond_2,edge_2,torch.tensor(d).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YCq678ziwSCp"
   },
   "outputs": [],
   "source": [
    "bs = train_params[\"batch_size\"]\n",
    "NUM_EPOCHS = train_params[\"epochs\"]\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "NUM_TRAIN = len(df)\n",
    "NUM_STEPS=ceil(NUM_TRAIN/bs)\n",
    "trainGen=train_generator(df,smiles,X_atoms, X_bonds, X_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pqStCk3Gx0Gt"
   },
   "outputs": [],
   "source": [
    "#num_workers=12 mporei na mpei ki ayto sto DataLoader\n",
    "train_loader = DataLoader(trainGen,\n",
    "                          batch_size=bs,\n",
    "                          num_workers=6,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ycamff-fylZu"
   },
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "  def __init__(self,dl,device):\n",
    "    self.dl=dl\n",
    "    self.device=device\n",
    "  def __iter__(self):\n",
    "    for b in self.dl:\n",
    "      yield to_device(b,self.device)\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"Number of batches\"\"\"\n",
    "    return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yzhetbkDzcHg"
   },
   "outputs": [],
   "source": [
    "train_loader=DeviceDataLoader(train_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bulwFm2-b6cF"
   },
   "outputs": [],
   "source": [
    "deepsiba=deepsiba.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RxRLCNtNzkAx"
   },
   "outputs": [],
   "source": [
    "adam = torch.optim.Adam(deepsiba.parameters(),lr=model_params[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(adam, 'min',factor=0.5,patience=3, min_lr=0.00001, eps=1e-5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Kz85rEr60TgQ"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  deepsiba.train()\n",
    "  for atom1,bond1,edge1,atom2,bond2,edge2,y_true in train_data_iterator:\n",
    "    #print(len(tb))\n",
    "    #tb = tb.to(dev)\n",
    "    adam.zero_grad()\n",
    "    \n",
    "    y_pred = deepsiba(atom1,bond1,edge1,atom2,bond2,edge2)\n",
    "    loss = custom_loss(y_true,y_pred)\n",
    "    r=r_square(y_true,y_pred)\n",
    "    pear=pearson_r(y_true,y_pred)\n",
    "    mse=custom_mse(y_true,y_pred)\n",
    "    mse_similars=mse_sliced(y_true,y_pred,0.2)\n",
    "    cindex=get_cindex(y_true,y_pred)\n",
    "    \n",
    "    train_data_iterator.set_postfix(\n",
    "        Epoch=epoch + 1,\n",
    "        r2='%.4f' % float(r),\n",
    "        pearson='%.4f' % float(pear),\n",
    "        Cindex='%.4f' % float(cindex),\n",
    "        Loss='%.4f' % float(loss.item()))\n",
    "    loss.backward()\n",
    "    #torch.nn.utils.clip_grad_norm_(model.encoder.emb_layer.parameters(), 0.05)\n",
    "    adam.step()\n",
    "\n",
    "  scheduler.step(loss)\n",
    "    \n",
    "    #del tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8z_5blR1Md-"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0870fcf18df496e99469fc6f89cd8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa666651503844f1aa7e7bbc653aa875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d90ad4a3e2482ea146db8bdd2aeb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2982952dc3fd49158a8bafa602a23293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c173ec6de4e943b2938e1b0993ed39b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2ca64d3fcb4d7a85763d45ad9dff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5cfa921109455c8c29022f0a53c0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "  train_data_iterator = tqdm(train_loader,\n",
    "                             leave=True,\n",
    "                             unit='batch',\n",
    "                             postfix={\n",
    "                                 'Epoch': epoch + 1,\n",
    "                                 'r2':'%.4f' % float(\"NaN\"),\n",
    "                                 'pearson':'%.4f' % float(\"NaN\"),\n",
    "                                 'Cindex':'%.4f' % float(\"NaN\"),\n",
    "                                 'Loss': '%.4f' % float(\"NaN\")})\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEZVacbCuPvB",
    "outputId": "dfc19078-0955-4794-c414-1664603660ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  7 20:26:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   76C    P0    46W /  70W |   1441MiB / 15079MiB |     50%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4zXDUAe3SiTL"
   },
   "outputs": [],
   "source": [
    "torch.save(deepsiba.state_dict(),'mymodel_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "erpHlvS3sIdL"
   },
   "outputs": [],
   "source": [
    "class preds_generator(Dataset):\n",
    "\n",
    "  def __init__(self, df_cold,smiles_cold,X_atoms_cold, X_bonds_cold, X_edges_cold):\n",
    "    self.df=df_cold\n",
    "    self.smiles=smiles_cold\n",
    "    self.X_atoms=X_atoms_cold\n",
    "    self.X_bonds=X_bonds_cold\n",
    "    self.X_edges=X_edges_cold\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    smi1=self.df['rdkit.x'][index]\n",
    "    smi2=self.df['rdkit.y'][index]\n",
    "    ind1=self.smiles.index(smi1)\n",
    "    ind2=self.smiles.index(smi2)\n",
    "    d=self.df.value[index]\n",
    "    atom_1=torch.tensor(self.X_atoms[ind1]).type(torch.FloatTensor)\n",
    "    bond_1=torch.tensor(self.X_bonds[ind1]).type(torch.FloatTensor)\n",
    "    edge_1=torch.tensor(self.X_edges[ind1]).type(torch.IntTensor)\n",
    "    atom_2=torch.tensor(self.X_atoms[ind2]).type(torch.FloatTensor)\n",
    "    bond_2=torch.tensor(self.X_bonds[ind2]).type(torch.FloatTensor)\n",
    "    edge_2=torch.tensor(self.X_edges[ind2]).type(torch.IntTensor)\n",
    "\n",
    "    return atom_1,bond_1,edge_1,atom_2,bond_2,edge_2,torch.tensor(d).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Q-5HV8oaulk1"
   },
   "outputs": [],
   "source": [
    "PredGen=preds_generator(df_cold,smiles_cold,X_atoms_cold, X_bonds_cold, X_edges_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TIbAPcubueHw"
   },
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(PredGen,\n",
    "                          batch_size=train_params[\"predict_batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Q2vONDhMu_P9"
   },
   "outputs": [],
   "source": [
    "eval_loader=DeviceDataLoader(eval_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "N6fGxm8pt9t7"
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "  with torch.no_grad():\n",
    "    deepsiba.eval()\n",
    "    y_pred1=[]\n",
    "    y_pred2=[]\n",
    "    for atom1,bond1,edge1,atom2,bond2,edge2,y_true in eval_data_iterator:\n",
    "      \n",
    "      y_pred = deepsiba(atom1,bond1,edge1,atom2,bond2,edge2)\n",
    "      y_pred = y_pred.cpu().numpy()\n",
    "      #y_pred=y_pred.to('cpu')\n",
    "      y_pred1=y_pred1+list(y_pred[:,0])\n",
    "      y_pred2=y_pred2+list(y_pred[:,1])\n",
    "\n",
    "  #y_pred1=torch.cat(y_pred1,dim=0)\n",
    "  #y_pred2=torch.cat(y_pred2,dim=0)\n",
    "\n",
    "  return y_pred1,y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "d8ce1350133c4ebca85742b668c02ff3",
      "c62bbb933de642c397e49af749f43995",
      "ac0f32f589244b238dd2edfbc3466916",
      "ed1475d2974445029a33b646dfee294f",
      "d1cb9667db244683a3da79c88069325d",
      "3f5cfc751aaf4e29951480ed0cc06a47",
      "3e8228a1982d4486ba83e3d711d63f62",
      "46cfb7e3c660478eb6b7098877a87409"
     ]
    },
    "id": "JGKebez7uI48",
    "outputId": "1867df23-a9a5-4d54-d934-1af1b1414b87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029d00888e1f4fae97150dea3d66b691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_data_iterator = tqdm(eval_loader,\n",
    "                          leave=True,\n",
    "                          unit='batch')\n",
    "y_pred1,y_pred2=predict()\n",
    "##kanta numpy arrays meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rPT2Q-fUTmIR"
   },
   "outputs": [],
   "source": [
    "y_pred1=np.array(y_pred1)\n",
    "y_pred2=np.array(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eExjBMBQv7CO"
   },
   "outputs": [],
   "source": [
    "if (len(y_pred1[np.where(y_pred1 <= train_params[\"prec_threshold\"])])>0):\n",
    "  get = model_evaluate(y_pred1,Y_cold,train_params[\"prec_threshold\"],df_cold)\n",
    "  #get.to_csv(train_params[\"output_dir\"] + \"/\" + \"fold_%s/performance/\"%i + \"model_%s.csv\"%n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "gsfg5FBbl0E2",
    "outputId": "c579bddc-48cc-43a3-9403-4667562db511"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>mse_all</th>\n",
       "      <th>mse_similars</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>FPR</th>\n",
       "      <th>positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.343229</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.27863</td>\n",
       "      <td>0.822438</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cor   mse_all  mse_similars  precision  accuracy       FPR  positives\n",
       "0  0.343229  0.012765      0.006214    0.27863  0.822438  0.016136        847"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxolapnPUG21",
    "outputId": "239d4b5a-1bd9-4509-95ee-328fa47bd6fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsiba.load_state_dict(torch.load('mymodel.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsustPObLdCd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xNjWmqKlLswf"
   },
   "outputs": [],
   "source": [
    "atoms=torch.tensor(X_atoms[0:5]).to(device)\n",
    "bonds=torch.tensor(X_bonds[0:5]).to(device)\n",
    "edges=torch.tensor(X_edges[0:5]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dimensions\n",
    "atoms_shape = list(atoms.size())\n",
    "batch_n = atoms_shape[0]\n",
    "lookup_size = atoms_shape[1]\n",
    "num_atom_features = atoms_shape[2]\n",
    "\n",
    "edges_shape = list(edges.size())\n",
    "max_atoms = edges_shape[1]\n",
    "max_degree = edges_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=5\n",
    "max_degree=5\n",
    "atom_feats=62\n",
    "max_atoms=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_degrees = torch.sum((~edges.eq(-1)).type(torch.cuda.FloatTensor), dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edges=torch.cat([torch.reshape(torch.linspace(0,max_atoms-1,60).type(torch.cuda.LongTensor).repeat(bs),(bs,max_atoms,1)),edges],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 62])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.reshape(atoms,(bs*max_atoms,atom_feats))[torch.reshape(new_edges,(bs*max_atoms,max_degree+1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=x.view(bs,max_atoms,max_degree+1,atom_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 6, 62])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_degrees[:,0:max_atoms,0].eq(degree).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(max_degree):\n",
    "    x[atom_degrees[:,0:max_atoms,0].eq(degree),:,(max_degree-degree+1):max_degree+1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 6, 62])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0uUL-XLIbDwK",
    "dNToVljcbglb",
    "O2Dn8Ckqbnw-"
   ],
   "name": "deepsiba_torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3e8228a1982d4486ba83e3d711d63f62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f5cfc751aaf4e29951480ed0cc06a47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46cfb7e3c660478eb6b7098877a87409": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac0f32f589244b238dd2edfbc3466916": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f5cfc751aaf4e29951480ed0cc06a47",
      "max": 45,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1cb9667db244683a3da79c88069325d",
      "value": 45
     }
    },
    "c62bbb933de642c397e49af749f43995": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1cb9667db244683a3da79c88069325d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d8ce1350133c4ebca85742b668c02ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac0f32f589244b238dd2edfbc3466916",
       "IPY_MODEL_ed1475d2974445029a33b646dfee294f"
      ],
      "layout": "IPY_MODEL_c62bbb933de642c397e49af749f43995"
     }
    },
    "ed1475d2974445029a33b646dfee294f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46cfb7e3c660478eb6b7098877a87409",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3e8228a1982d4486ba83e3d711d63f62",
      "value": " 45/45 [00:15&lt;00:00,  2.86batch/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
