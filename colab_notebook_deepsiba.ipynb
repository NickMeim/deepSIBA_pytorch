{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepsiba_torch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0uUL-XLIbDwK",
        "dNToVljcbglb",
        "O2Dn8Ckqbnw-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8ce1350133c4ebca85742b668c02ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c62bbb933de642c397e49af749f43995",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac0f32f589244b238dd2edfbc3466916",
              "IPY_MODEL_ed1475d2974445029a33b646dfee294f"
            ]
          }
        },
        "c62bbb933de642c397e49af749f43995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac0f32f589244b238dd2edfbc3466916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1cb9667db244683a3da79c88069325d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 45,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 45,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f5cfc751aaf4e29951480ed0cc06a47"
          }
        },
        "ed1475d2974445029a33b646dfee294f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e8228a1982d4486ba83e3d711d63f62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45/45 [00:15&lt;00:00,  2.86batch/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46cfb7e3c660478eb6b7098877a87409"
          }
        },
        "d1cb9667db244683a3da79c88069325d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f5cfc751aaf4e29951480ed0cc06a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e8228a1982d4486ba83e3d711d63f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46cfb7e3c660478eb6b7098877a87409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uUL-XLIbDwK"
      },
      "source": [
        "# Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPFWQDo-a-yV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01d9c70-d4c7-4ef2-9196-4de90cdd7f5f"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        "\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        "\n",
        "\n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        "\n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        "\n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        "\n",
        "        logger.info(\"force re-install\")\n",
        "\n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        "\n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        "\n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        "\n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python=={}\".format(python_version),\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        "\n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "python version: 3.6.9\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit\n",
            "done\n",
            "rdkit-2020.09.1 installation finished!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F510HBNbGA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58173ff-f5d3-44af-ab6f-669a5f6fc5ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG5guXisbJ4t"
      },
      "source": [
        "!cp -r \"drive/My Drive/deepSIBA_pytorch/NGF\" /content\n",
        "!cp -r \"drive/My Drive/deepSIBA_pytorch/NGF_layers\" /content\n",
        "!cp -r \"drive/My Drive/deepSIBA_pytorch/utility\" /content\n",
        "!cp -r \"drive/My Drive/deepSIBA_pytorch/utils\" /content\n",
        "!cp -r \"drive/My Drive/deepsiba_tf2/data\" /content\n",
        "!cp \"drive/My Drive/deepSIBA_pytorch/deepSIBA_model.py\" /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5elLBIKsmeUZ"
      },
      "source": [
        "#!rm -r NGF_layers\n",
        "#!rm -r utility\n",
        "#!rm -r utils\n",
        "#!rm -r data\n",
        "#!rm deepSIBA_model.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POgMJkNybKwp"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from numpy import inf, ndarray\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import sklearn\n",
        "import re\n",
        "#from NGF.utils import filter_func_args, mol_shapes_to_dims\n",
        "#import NGF.utils\n",
        "import NGF_layers.features\n",
        "import NGF_layers.graph_layers\n",
        "from NGF_layers.features import one_of_k_encoding, one_of_k_encoding_unk, atom_features, bond_features, num_atom_features, num_bond_features, padaxis, tensorise_smiles #, concat_mol_tensors\n",
        "from NGF_layers.graph_layers import temporal_padding, neighbour_lookup, NeuralGraphHidden\n",
        "from math import ceil\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from utility.gaussian import GaussianLayer, custom_loss, ConGaussianLayer\n",
        "from utility.evaluator import r_square, get_cindex, pearson_r,custom_mse, mse_sliced, model_evaluate\n",
        "from utility.Generator import train_generator,preds_generator\n",
        "from deepSIBA_model import enc_graph, siamese_model\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNToVljcbglb"
      },
      "source": [
        "# Load train and model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAVULcElbbVX"
      },
      "source": [
        "#model_params\n",
        "model_params = {\n",
        "    \"max_atoms\" : int(60), \"num_atom_features\" : int(62), \"max_degree\" : int(5), \"num_bond_features\" : int(6),\n",
        "    \"graph_conv_width\" : [128,128,128], \"conv1d_in\" : int(60), \"conv1d_out\" : int(32), \"kernel_size\" : int(1), \"dropout_encoder\" : 0.25,\n",
        "    \"conv1d_dist_in\" : [32,16], \"conv1d_dist_out\" : [16,16], \"conv1d_dist_kernels\" : [1,1], \"dropout_dist\" : 0.25, \"pool_size\" : int(4),\n",
        "    \"dense_size\" : [256,128,128], \"l2reg\" : 0.01, \"dist_thresh\" : 0.2, \"lr\" : 0.001 ,\"ConGauss\": False\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr32VyDYbi4A"
      },
      "source": [
        "train_params = {\n",
        "    \"cell_line\" : \"a375\", \"split\" : \"train_test_split\", \"number_folds\" : [0],\n",
        "    \"output_dir\" : \"results\",\n",
        "    \"batch_size\" : int(128), \"epochs\" : int(20), \n",
        "    \"N_ensemble\" : int(1), \"nmodel_start\" : int(0), \"prec_threshold\" : 0.2,\n",
        "    \"Pre_training\" : False,\n",
        "    \"Pre_trained_cell_dir\" : '',\n",
        "    \"pattern_to_load\" : 'siam_no_augment_',\n",
        "    \"model_id_to_load\" : \"20\",\n",
        "    \"test_value_norm\" : True,\n",
        "    \"predict_batch_size\":int(1024)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Dn8Ckqbnw-"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzqITRqFbklm"
      },
      "source": [
        "get_all = []\n",
        "if train_params[\"split\"] == \"train_test_split\":\n",
        "  outer_loop = train_params[\"number_folds\"]\n",
        "elif train_params[\"split\"] == \"5_fold_cv_split\":\n",
        "  outer_loop = train_params[\"number_folds\"]\n",
        "elif train_params[\"split\"] == \"alldata\":\n",
        "  outer_loop = train_params[\"number_folds\"]\n",
        "#Load unique smiles and tensorize them\n",
        "smiles = pd.read_csv(\"data/\" + train_params[\"cell_line\"] + \"/\" + train_params[\"cell_line\"] + \"q1smiles.csv\", index_col=0)\n",
        "X_atoms, X_bonds, X_edges = tensorise_smiles(smiles.x, model_params[\"max_degree\"], model_params[\"max_atoms\"])\n",
        "smiles=list(smiles['x'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHg9So9brV9"
      },
      "source": [
        "df = pd.read_csv(\"data/\" + train_params[\"cell_line\"] + \"/\" + \"train_test_split/\" + \"train.csv\",index_col=0).reset_index(drop=True)\n",
        "df_cold = pd.read_csv(\"data/\" + train_params[\"cell_line\"] + \"/\" + \"train_test_split/\" + \"test.csv\",index_col=0).reset_index(drop=True)\n",
        "smiles_cold = list(set(list(df_cold['rdkit.x'])+list(df_cold['rdkit.y'])))\n",
        "X_atoms_cold, X_bonds_cold, X_edges_cold = tensorise_smiles(smiles_cold,  model_params[\"max_degree\"], model_params[\"max_atoms\"])\n",
        "#X_atoms_cold=X_atoms_cold.astype('float64')\n",
        "#X_bonds_cold=X_bonds_cold.astype('float64')\n",
        "#X_edges_cold=X_edges_cold.astype('int64')\n",
        "if train_params[\"test_value_norm\"]:\n",
        "  Y_cold = df_cold.value\n",
        "else:\n",
        "  Y_cold = df_cold.value\n",
        "  Y_cold = Y_cold/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi-Nsmo4btqZ"
      },
      "source": [
        "i=0\n",
        "Path(train_params[\"output_dir\"] + \"/\" + \"fold_%s/models\"%i).mkdir(parents=True, exist_ok=True)\n",
        "cold_preds_mus = []\n",
        "cold_preds_sigmas = []\n",
        "n = train_params[\"nmodel_start\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWnFEBkmbyVa"
      },
      "source": [
        "# Define,Compile,Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paXMLg2-bvyd"
      },
      "source": [
        "deepsiba = siamese_model(model_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-iVqiwjwk0T",
        "outputId": "1d07ca21-cc47-4fe0-e4a0-f0700121f0fe"
      },
      "source": [
        "def get_default_device():\n",
        "  if torch.cuda.is_available():\n",
        "    print('cuda mode')\n",
        "    return torch.device('cuda')\n",
        "  else:\n",
        "    print('cpu mode')\n",
        "  return torch.device('cpu')\n",
        "device=get_default_device()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooinemLwxJbf"
      },
      "source": [
        "def to_device(data,device):\n",
        "  if isinstance(data,(list,tuple)):\n",
        "    return [to_device(x,device) for x in data]\n",
        "  return data.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4VhB7fwDrD"
      },
      "source": [
        "class train_generator(Dataset):\n",
        "\n",
        "  def __init__(self, data,smiles,X_atoms, X_bonds, X_edges):\n",
        "    self.df=data\n",
        "    self.smiles=smiles\n",
        "    self.X_atoms=X_atoms\n",
        "    self.X_bonds=X_bonds\n",
        "    self.X_edges=X_edges\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    smi1=self.df['rdkit.x'][index]\n",
        "    smi2=self.df['rdkit.y'][index]\n",
        "    d=self.df.value[index]/2\n",
        "    ind1=self.smiles.index(smi1)\n",
        "    ind2=self.smiles.index(smi2)\n",
        "    atom_1=torch.tensor(self.X_atoms[ind1]).type(torch.FloatTensor)\n",
        "    bond_1=torch.tensor(self.X_bonds[ind1]).type(torch.FloatTensor)\n",
        "    edge_1=torch.tensor(self.X_edges[ind1]).type(torch.IntTensor)\n",
        "    atom_2=torch.tensor(self.X_atoms[ind2]).type(torch.FloatTensor)\n",
        "    bond_2=torch.tensor(self.X_bonds[ind2]).type(torch.FloatTensor)\n",
        "    edge_2=torch.tensor(self.X_edges[ind2]).type(torch.IntTensor)\n",
        "    return atom_1,bond_1,edge_1,atom_2,bond_2,edge_2,torch.tensor(d).type(torch.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCq678ziwSCp"
      },
      "source": [
        "bs = train_params[\"batch_size\"]\n",
        "NUM_EPOCHS = train_params[\"epochs\"]\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "NUM_TRAIN = len(df)\n",
        "NUM_STEPS=ceil(NUM_TRAIN/bs)\n",
        "trainGen=train_generator(df,smiles,X_atoms, X_bonds, X_edges)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqStCk3Gx0Gt"
      },
      "source": [
        "#num_workers=12 mporei na mpei ki ayto sto DataLoader\n",
        "train_loader = DataLoader(trainGen,\n",
        "                          batch_size=bs,\n",
        "                          num_workers=2,\n",
        "                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycamff-fylZu"
      },
      "source": [
        "class DeviceDataLoader():\n",
        "  def __init__(self,dl,device):\n",
        "    self.dl=dl\n",
        "    self.device=device\n",
        "  def __iter__(self):\n",
        "    for b in self.dl:\n",
        "      yield to_device(b,self.device)\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Number of batches\"\"\"\n",
        "    return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzhetbkDzcHg"
      },
      "source": [
        "train_loader=DeviceDataLoader(train_loader,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bulwFm2-b6cF"
      },
      "source": [
        "deepsiba=deepsiba.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRLCNtNzkAx"
      },
      "source": [
        "adam = torch.optim.Adam(deepsiba.parameters(),lr=model_params[\"lr\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(adam, 'min',factor=0.5,patience=3, min_lr=0.00001, eps=1e-5,verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz85rEr60TgQ"
      },
      "source": [
        "def train(epoch):\n",
        "  deepsiba.train()\n",
        "  for atom1,bond1,edge1,atom2,bond2,edge2,y_true in train_data_iterator:\n",
        "    #print(len(tb))\n",
        "    #tb = tb.to(dev)\n",
        "    adam.zero_grad()\n",
        "    \n",
        "    y_pred = deepsiba(atom1,bond1,edge1,atom2,bond2,edge2)\n",
        "    loss = custom_loss(y_true,y_pred)\n",
        "    r=r_square(y_true,y_pred)\n",
        "    pear=pearson_r(y_true,y_pred)\n",
        "    mse=custom_mse(y_true,y_pred)\n",
        "    mse_similars=mse_sliced(y_true,y_pred,0.2)\n",
        "    cindex=get_cindex(y_true,y_pred)\n",
        "    \n",
        "    train_data_iterator.set_postfix(\n",
        "        Epoch=epoch + 1,\n",
        "        r2='%.4f' % float(r),\n",
        "        pearson='%.4f' % float(pear),\n",
        "        Cindex='%.4f' % float(cindex),\n",
        "        Loss='%.4f' % float(loss.item()))\n",
        "    loss.backward()\n",
        "    #torch.nn.utils.clip_grad_norm_(model.encoder.emb_layer.parameters(), 0.05)\n",
        "    adam.step()\n",
        "\n",
        "  scheduler.step(loss)\n",
        "    \n",
        "    #del tb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8z_5blR1Md-"
      },
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_data_iterator = tqdm(train_loader,\n",
        "                             leave=True,\n",
        "                             unit='batch',\n",
        "                             postfix={\n",
        "                                 'Epoch': epoch + 1,\n",
        "                                 'r2':'%.4f' % float(\"NaN\"),\n",
        "                                 'pearson':'%.4f' % float(\"NaN\"),\n",
        "                                 'Cindex':'%.4f' % float(\"NaN\"),\n",
        "                                 'Loss': '%.4f' % float(\"NaN\")})\n",
        "  train(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEZVacbCuPvB",
        "outputId": "dfc19078-0955-4794-c414-1664603660ef"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec  7 20:26:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    46W /  70W |   1441MiB / 15079MiB |     50%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zXDUAe3SiTL"
      },
      "source": [
        "torch.save(deepsiba.state_dict(),'mymodel_3.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erpHlvS3sIdL"
      },
      "source": [
        "class preds_generator(Dataset):\n",
        "\n",
        "  def __init__(self, df_cold,smiles_cold,X_atoms_cold, X_bonds_cold, X_edges_cold):\n",
        "    self.df=df_cold\n",
        "    self.smiles=smiles_cold\n",
        "    self.X_atoms=X_atoms_cold\n",
        "    self.X_bonds=X_bonds_cold\n",
        "    self.X_edges=X_edges_cold\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    smi1=self.df['rdkit.x'][index]\n",
        "    smi2=self.df['rdkit.y'][index]\n",
        "    ind1=self.smiles.index(smi1)\n",
        "    ind2=self.smiles.index(smi2)\n",
        "    d=self.df.value[index]\n",
        "    atom_1=torch.tensor(self.X_atoms[ind1]).type(torch.FloatTensor)\n",
        "    bond_1=torch.tensor(self.X_bonds[ind1]).type(torch.FloatTensor)\n",
        "    edge_1=torch.tensor(self.X_edges[ind1]).type(torch.IntTensor)\n",
        "    atom_2=torch.tensor(self.X_atoms[ind2]).type(torch.FloatTensor)\n",
        "    bond_2=torch.tensor(self.X_bonds[ind2]).type(torch.FloatTensor)\n",
        "    edge_2=torch.tensor(self.X_edges[ind2]).type(torch.IntTensor)\n",
        "\n",
        "    return atom_1,bond_1,edge_1,atom_2,bond_2,edge_2,torch.tensor(d).type(torch.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-5HV8oaulk1"
      },
      "source": [
        "PredGen=preds_generator(df_cold,smiles_cold,X_atoms_cold, X_bonds_cold, X_edges_cold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIbAPcubueHw"
      },
      "source": [
        "eval_loader = DataLoader(PredGen,\n",
        "                          batch_size=train_params[\"predict_batch_size\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2vONDhMu_P9"
      },
      "source": [
        "eval_loader=DeviceDataLoader(eval_loader,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6fGxm8pt9t7"
      },
      "source": [
        "def predict():\n",
        "  with torch.no_grad():\n",
        "    deepsiba.eval()\n",
        "    y_pred1=[]\n",
        "    y_pred2=[]\n",
        "    for atom1,bond1,edge1,atom2,bond2,edge2,y_true in eval_data_iterator:\n",
        "      \n",
        "      y_pred = deepsiba(atom1,bond1,edge1,atom2,bond2,edge2)\n",
        "      y_pred = y_pred.cpu().numpy()\n",
        "      #y_pred=y_pred.to('cpu')\n",
        "      y_pred1=y_pred1+list(y_pred[:,0])\n",
        "      y_pred2=y_pred2+list(y_pred[:,1])\n",
        "\n",
        "  #y_pred1=torch.cat(y_pred1,dim=0)\n",
        "  #y_pred2=torch.cat(y_pred2,dim=0)\n",
        "\n",
        "  return y_pred1,y_pred2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGKebez7uI48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d8ce1350133c4ebca85742b668c02ff3",
            "c62bbb933de642c397e49af749f43995",
            "ac0f32f589244b238dd2edfbc3466916",
            "ed1475d2974445029a33b646dfee294f",
            "d1cb9667db244683a3da79c88069325d",
            "3f5cfc751aaf4e29951480ed0cc06a47",
            "3e8228a1982d4486ba83e3d711d63f62",
            "46cfb7e3c660478eb6b7098877a87409"
          ]
        },
        "outputId": "1867df23-a9a5-4d54-d934-1af1b1414b87"
      },
      "source": [
        "eval_data_iterator = tqdm(eval_loader,\n",
        "                          leave=True,\n",
        "                          unit='batch')\n",
        "y_pred1,y_pred2=predict()\n",
        "##kanta numpy arrays meta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8ce1350133c4ebca85742b668c02ff3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPT2Q-fUTmIR"
      },
      "source": [
        "y_pred1=np.array(y_pred1)\n",
        "y_pred2=np.array(y_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExjBMBQv7CO"
      },
      "source": [
        "if (len(y_pred1[np.where(y_pred1 <= train_params[\"prec_threshold\"])])>0):\n",
        "  get = model_evaluate(y_pred1,Y_cold,train_params[\"prec_threshold\"],df_cold)\n",
        "  #get.to_csv(train_params[\"output_dir\"] + \"/\" + \"fold_%s/performance/\"%i + \"model_%s.csv\"%n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "gsfg5FBbl0E2",
        "outputId": "c579bddc-48cc-43a3-9403-4667562db511"
      },
      "source": [
        "get"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cor</th>\n",
              "      <th>mse_all</th>\n",
              "      <th>mse_similars</th>\n",
              "      <th>precision</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>FPR</th>\n",
              "      <th>positives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.187766</td>\n",
              "      <td>0.04369</td>\n",
              "      <td>0.142475</td>\n",
              "      <td>0.334512</td>\n",
              "      <td>0.748552</td>\n",
              "      <td>0.198759</td>\n",
              "      <td>11309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        cor  mse_all  mse_similars  precision  accuracy       FPR  positives\n",
              "0  0.187766  0.04369      0.142475   0.334512  0.748552  0.198759      11309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxolapnPUG21",
        "outputId": "239d4b5a-1bd9-4509-95ee-328fa47bd6fb"
      },
      "source": [
        "deepsiba.load_state_dict(torch.load('mymodel.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsustPObLdCd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNjWmqKlLswf"
      },
      "source": [
        "atoms=torch.tensor(X_atoms[0:5]).to(device)\r\n",
        "bonds=torch.tensor(X_bonds[0:5]).to(device)\r\n",
        "edges=torch.tensor(X_edges[0:5]).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}